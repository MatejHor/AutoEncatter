{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding Seed so that random initialization is consistent\n",
    "import os\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset\n",
    "\n",
    "#Prepare input data\n",
    "train_path='training_data'\n",
    "classes = ['cats']\n",
    "print(classes)\n",
    "num_classes = len(classes)\n",
    "\n",
    "# 10% of the data will automatically be used for validation\n",
    "validation_size = 0.1\n",
    "img_size = 48\n",
    "num_channels = 3\n",
    "sample_size = 8192\n",
    "\n",
    "data = dataset.read_train_sets(train_path, img_size, ['cats'], validation_size=validation_size, sample_size=sample_size)\n",
    "\n",
    "\n",
    "print(\"Complete reading input data. Will Now print a snippet of it\")\n",
    "print(\"Number of files in Training-set:\\t\\t{}\".format(len(data.train.labels)))\n",
    "print(\"Number of files in Validation-set:\\t{}\".format(len(data.valid.labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the AutoEncoder with three hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "total_pixels = img_size * img_size * 3\n",
    "translator_factor = 2\n",
    "translator_layer_size = int(total_pixels/translator_factor)\n",
    "middle_factor = 2\n",
    "middle_layer_size = int(translator_layer_size/middle_factor)\n",
    "\n",
    "inputs = keras.Input(shape=(img_size,img_size,3), name='cat_image')\n",
    "x = layers.Flatten(name = 'flattened_cat')(inputs) #49152 #3072\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dense(translator_layer_size, activation='relu', name='encoder')(x)\n",
    "x = layers.Dense(middle_layer_size, activation='relu', name='middle_layer')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dense(translator_layer_size, activation='relu', name='decoder')(x)\n",
    "\n",
    "outputs = layers.Dense(total_pixels, activation='sigmoid', name='reconstructed_cat')(x)\n",
    "outputs = layers.Reshape((img_size,img_size,3))(outputs)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customAdam = keras.optimizers.Adam(lr=0.001)\n",
    "model.compile(optimizer=customAdam,  # Optimizer\n",
    "              # Loss function to minimize\n",
    "              loss=\"mean_squared_error\",\n",
    "              # List of metrics to monitor\n",
    "              metrics=[\"mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, _, _, _ = data.train.next_batch(7373)\n",
    "x_valid, _, _, _ = data.valid.next_batch(819)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# Fit model on training data')\n",
    "\n",
    "history = model.fit(x_train, \n",
    "                    x_train, #we pass it the input itself as desired output\n",
    "                    batch_size=256,\n",
    "                    epochs=2,\n",
    "                    # We pass it validation data to\n",
    "                    # monitor loss and metrics\n",
    "                    # at the end of each epoch\n",
    "                    validation_data=(x_valid, x_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "valid_predictions = model.predict(x_valid[:40])\n",
    "for index in range(20):\n",
    "    instance = x_valid[index]\n",
    "    decoded_img = valid_predictions[index]\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    subplot = plt.subplot(2, 10, 1)\n",
    "    plt.imshow(instance)\n",
    "\n",
    "    subplot.get_xaxis().set_visible(False)\n",
    "    subplot.get_yaxis().set_visible(False)\n",
    "\n",
    "    subplot = plt.subplot(2, 10, 2)\n",
    "    plt.imshow(decoded_img)\n",
    "\n",
    "    subplot.get_xaxis().set_visible(False)\n",
    "    subplot.get_yaxis().set_visible(False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
